{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validated DVs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re\n",
    "sys.path.insert(1, '../../../figure_code/')\n",
    "from my_imports import *\n",
    "import pingouin as pg\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from helpers.phys_helpers import get_sortCells_for_rat, equalize_neurons_across_regions, datetime, savethisfig, xcorr\n",
    "from helpers.rasters_and_psths import get_neural_activity\n",
    "from helpers.physdata_preprocessing import load_phys_data_from_Cell\n",
    "from scipy import stats\n",
    "from DVcc_sims import crosscorrelate_DVs, plot_cc\n",
    "\n",
    "def get_filenames(decoding_dir):\n",
    "    filenames = sorted([fn for fn in os.listdir(decoding_dir) if re.findall(\".npy\", fn)])\n",
    "    param_file = [fn for fn in filenames if 'params' in fn][0]  \n",
    "    p = np.load(decoding_dir + param_file, allow_pickle = True).item()\n",
    "    filenames.remove(param_file)\n",
    "    return p, filenames\n",
    "\n",
    "\n",
    "CH_DECODING_DIR = 'DV_decoding/'\n",
    "SAVEDIR = SPEC.RESULTDIR + 'DV_decoding/'\n",
    "\n",
    "this_dir = os.path.join(SPEC.RESULTDIR, CH_DECODING_DIR)\n",
    "p, filenames = get_filenames(this_dir)\n",
    "\n",
    "p['binsize'] = 5  # in ms, to get at latencies\n",
    "p['filter_w'] = 50  # in ms, still need to smooth a bit\n",
    "p['filter_type'] = 'gaussian'\n",
    "p['end_time'] = [800]\n",
    "\n",
    "\n",
    "DV_summary = dict()\n",
    "for var in ['DV_cc', 'DV_peak', 'DV_cc_shuff', 'lags']:\n",
    "    DV_summary[var] = []\n",
    "    \n",
    "align_id = 0\n",
    "align_to = p['align_to'][align_id]\n",
    "align_name = p['align_name'][align_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filenum, fn in enumerate(filenames):\n",
    "\n",
    "    summary = np.load(this_dir + fn, allow_pickle=True).item()\n",
    "    rat = summary['prm']['filename'][:4]\n",
    "\n",
    "    print(rat)\n",
    "    _, this_datadir = get_sortCells_for_rat(rat, SPEC.DATADIR)\n",
    "\n",
    "\n",
    "    df_trial, df_cell, _ = load_phys_data_from_Cell(\n",
    "    this_datadir + os.sep + summary['prm']['filename'])\n",
    "\n",
    "    summary = summary['clickson_masked']\n",
    "\n",
    "    df_trial = df_trial[df_trial['stim_dur_s_actual']\n",
    "                    >= p['stim_thresh']].reset_index(drop=True)\n",
    "\n",
    "    # equalize neurons across regions\n",
    "    df_cell = df_cell[df_cell['stim_fr'] >= p['fr_thresh']].reset_index(drop=True)\n",
    "    df_cell = equalize_neurons_across_regions(df_cell, p['regions'])\n",
    "\n",
    "    # equalize left right trials\n",
    "    random.seed(10)\n",
    "    n = df_trial['pokedR'].value_counts().min()\n",
    "    idx_R = random.sample(list(np.where(df_trial['pokedR'] == 1)[0]), n)[:n]\n",
    "    idx_L = random.sample(list(np.where(df_trial['pokedR'] == 0)[0]), n)[:n]\n",
    "    df_trial = df_trial.loc[np.sort(idx_R + idx_L)].reset_index(drop=True)\n",
    "    ntrials = len(df_trial)\n",
    "    print(\"trial_count: {}\".format(ntrials))\n",
    "\n",
    "    X = dict()\n",
    "    X = dict()\n",
    "    for reg in p['regions']:\n",
    "        X[reg], ntpts_per_trial = get_neural_activity(\n",
    "            df_cell, df_trial, reg, p, align_id)\n",
    "        \n",
    "    idx_trial = np.concatenate(([0], np.cumsum(ntpts_per_trial)))\n",
    "    max_tpts = max(ntpts_per_trial)\n",
    "    num_trials = len(ntpts_per_trial)\n",
    "    \n",
    "    DV = dict()\n",
    "    for reg in p['regions']:\n",
    "        DV[reg] = np.nan * np.zeros((num_trials, max_tpts))\n",
    "        cv_dict = summary[reg]['cv_summary'][0]\n",
    "        for fold in range(p['nfolds']):\n",
    "            for tidx in cv_dict['test_trials'][fold]:\n",
    "                mdl_coefs = cv_dict['mdl_coefs'][fold]\n",
    "                intercept = cv_dict['mdl_intercept'][fold]\n",
    "                this_slice = slice(idx_trial[tidx], idx_trial[tidx + 1])\n",
    "                test_index = np.arange(this_slice.start, this_slice.stop)\n",
    "                DV[reg][tidx, 0:ntpts_per_trial[tidx]] = mdl_coefs @ X[reg][:,test_index] + intercept\n",
    "            \n",
    "    # cross correlate DVs\n",
    "    DV_cc = crosscorrelate_DVs(DV, p, shuffle = False)\n",
    "    DV_cc_shuff = crosscorrelate_DVs(DV, p, shuffle = True)\n",
    "\n",
    "    \n",
    "    \n",
    "    DV_summary['DV_cc'].append(DV_cc['mean'])\n",
    "    DV_summary['DV_peak'].append(DV_cc['peak'])\n",
    "    DV_summary['DV_cc_shuff'].append(DV_cc_shuff['mean'])\n",
    "    DV_summary['lags'].append(DV_cc['lags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot cross-correlation \n",
    "fig = plt.figure(figsize = (6,5))\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "ax = fig.gca()\n",
    "\n",
    "compute_shuffle = True\n",
    "\n",
    "def get_DV_cc(DV_summary, compute_shuffle):\n",
    "    if compute_shuffle:\n",
    "        var = 'DV_cc_shuff'\n",
    "    else:\n",
    "        var = 'DV_cc'\n",
    "    # i should make sure all the lags are the same!!\n",
    "    DV_cc = dict()\n",
    "    DV_cc['lags'] = DV_summary['lags'][0]\n",
    "    DV_cc['mean'] = np.nanmean(DV_summary[var], axis = 0)\n",
    "    DV_cc['sem'] = np.nanstd(DV_summary[var], axis = 0)/np.sqrt(len(DV_summary[var]))\n",
    "    peak_idx = np.argmax(DV_cc['mean'])\n",
    "    DV_cc['peak'] = DV_cc['lags'][peak_idx] \n",
    "    \n",
    "    return DV_cc\n",
    "\n",
    "plot_cc(get_DV_cc(DV_summary, False), 'k', ax, 'Mean across rats', alpha = 0.5)\n",
    "ax.axvline(DV_cc['peak'], c = 'k', ls = '--')\n",
    "plot_cc(get_DV_cc(DV_summary, True), [0.5, 0.5, 0.5], ax, 'shuffle', alpha = 0.2)\n",
    "ax.legend(frameon = False)\n",
    "ax.axvline(0, c = 'k', ls = ':')\n",
    "ax.axhline(0, c = 'k',ls = ':')\n",
    "ax.set_xlim([-0.4, 0.4])\n",
    "ax.set_xlabel('Lags [s]')\n",
    "ax.set_ylabel('CV Decision variable \\n correlation (ADS, FOF) $\\pm$ SEM')\n",
    "ax.set_ylim([-0.1, 1.2])\n",
    "for r, reg in enumerate(np.flip(p['regions'])):\n",
    "    ax.text(-0.1 + r*0.2,  \n",
    "        ax.get_ylim()[1], \n",
    "        reg + ' leads', \n",
    "        fontsize=16, \n",
    "        va='center', \n",
    "        ha='center', \n",
    "        backgroundcolor='w')\n",
    "sns.despine()\n",
    "\n",
    "peaks = DV_summary['DV_peak']\n",
    "# Perform one-sample t-test\n",
    "t_statistic, p_value = stats.ttest_1samp(peaks, 0)\n",
    "\n",
    "# Print results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print(\"Mean peak: {}\".format(np.mean(peaks)))\n",
    "savethisfig(SPEC.FIGUREDIR, 'figure2/figure2_DV_crosscorrelation')\n",
    "\n",
    "\n",
    "output_file = open(SPEC.RESULTDIR + \"figure2_DV_summary.txt\",'w')\n",
    "print(\"\\n\\nT-test for to check if peak is different from 0 for %s sessions\" % len(peaks), file = output_file)\n",
    "print(\"\\nMean peak: {}\".format(np.mean(peaks)), file= output_file)\n",
    "print(\"\\nsem: {}\".format(np.std(peaks)/np.sqrt(len(peaks))), file= output_file)\n",
    "print(\"\\nT-statistic: {}\".format(t_statistic), file= output_file)\n",
    "print(\"\\nP-value: {}\".format(p_value), file= output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVcc_sims plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DVcc_sims import *\n",
    "sns.set_context(\"talk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_neurons = 20\n",
    "N_trials = 200\n",
    "ff_delays = 5\n",
    "\n",
    "# for simulations\n",
    "params = dict()\n",
    "params['dt'] = 0.001\n",
    "params['history_bias'] = True\n",
    "params['bound'] = 8.\n",
    "params['leak'] = 0.99\n",
    "params['T'] = [0.2, 1.0]\n",
    "\n",
    "\n",
    "\n",
    "# for decoding\n",
    "p = dict()\n",
    "p['regions'] = ['A', 'B']\n",
    "p['cols'] = SPEC.COLS\n",
    "p['fr_thresh'] = 1.0 # firing rate threshold for including neurons\n",
    "p['stim_thresh'] = 0.0 # stimulus duration threshold for including trials\n",
    "p['align_to'] = ['clicks_on']\n",
    "p['align_name'] = ['clickson_masked']\n",
    "p['pre_mask'] = [None]\n",
    "p['post_mask'] = ['clicks_off']\n",
    "p['start_time'] = [0,]\n",
    "p['end_time'] = [1000] # in ms\n",
    "p['binsize'] = 50 # in ms\n",
    "p['filter_type'] = 'gaussian'\n",
    "p['filter_w'] = 75 # in ms\n",
    "p['Cs'] = np.logspace(-7,3,200)  # cross-validation parameter\n",
    "p['nfolds'] = 10  # number of folds for cross-validation\n",
    "p['n_repeats'] = 1 # number of repeats for cross-validation\n",
    "\n",
    "\n",
    "# for DV cross correlations\n",
    "prm = dict()\n",
    "prm['regions'] = ['A', 'B']\n",
    "prm['cols'] = SPEC.COLS\n",
    "prm['align_to'] = ['clicks_on']\n",
    "prm['align_name'] = ['clickson_masked']\n",
    "prm['pre_mask'] = [None]\n",
    "prm['post_mask'] = ['clicks_off']\n",
    "prm['start_time'] = [0]\n",
    "prm['end_time'] = [800] # in ms\n",
    "prm['binsize'] = 5 # in ms\n",
    "prm['filter_type'] = 'gaussian'\n",
    "prm['filter_w'] = 50 # in ms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data\n",
    "pc_task = PoissonClicks(**params)\n",
    "ns = NeuralSimulator(**params)\n",
    "click_data, task_data = pc_task.get_trial_batch()\n",
    "latents, spikes, spike_rate_dt, task_data = ns.simulate_trials(click_data, task_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dyn = plt.figure(constrained_layout = True, figsize = (12,8))\n",
    "gs = fig_dyn.add_gridspec(5,4, width_ratios=[10,10,5,1])\n",
    "\n",
    "xlabel_dyn = ns.get_latents_labels()\n",
    "\n",
    "# dynamics matrix during accumulation\n",
    "ax0 = fig_dyn.add_subplot(gs[0:2, 0])\n",
    "im = ax0.matshow(ns.A[0], cmap = 'Blues', vmin = 0., vmax = 1.)\n",
    "ax0.set_title('$A_{acc}$')\n",
    "ax0.set_yticks(ticks = range(2*ns.N_latents_per_region), labels = xlabel_dyn)\n",
    "ax0.set_xticks(ticks = range(2*ns.N_latents_per_region), labels = xlabel_dyn, rotation = 90)\n",
    "\n",
    "\n",
    "# dynamics matrix during accumulation\n",
    "ax0 = fig_dyn.add_subplot(gs[0:2, 1])\n",
    "ax0.matshow(ns.A_delay[0], cmap = 'Blues', vmin = 0., vmax = 1.)\n",
    "ax0.set_title('$A^{ff}_{acc}$')\n",
    "ax0.set_yticks(ticks = range(2*ns.N_latents_per_region), labels = xlabel_dyn)\n",
    "ax0.set_xticks(ticks = range(2*ns.N_latents_per_region), labels = xlabel_dyn, rotation = 90);\n",
    "\n",
    "# dynamics matrix during accumulation\n",
    "ax0 = fig_dyn.add_subplot(gs[0:2, 2])\n",
    "ax0.matshow(ns.B[0], cmap = 'Blues', vmin = 0., vmax = 1.)\n",
    "ax0.set_title('$B_{acc}$')\n",
    "ax0.set_yticks(ticks = range(2*ns.N_latents_per_region), labels = xlabel_dyn)\n",
    "ax0.set_xticks(ticks = [0,1], labels = { 'δR-δL', 'history'}, rotation = 45)\n",
    "\n",
    "# add the colorbar at the top of the plot\n",
    "ax0 = fig_dyn.add_subplot(gs[0:2, 3])\n",
    "cbar = plt.colorbar(im, cax=ax0, orientation='vertical')\n",
    "\n",
    "\n",
    "ax0 = fig_dyn.add_subplot(gs[3, :])\n",
    "ax0.matshow(ns.C.T, vmin = -2, vmax = 2, cmap = 'RdBu', aspect = 'auto')\n",
    "ax0.set_xlabel('Neuron number')\n",
    "ax0.set_ylabel('Latents')\n",
    "ax0.set_title('$C$')\n",
    "ax0.set_yticks(ticks = range(2*ns.N_latents_per_region), labels = xlabel_dyn)\n",
    "\n",
    "\n",
    "savethisfig(SPEC.FIGUREDIR + \"figure2/\", 'figure2_DVsweeps_params')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "\n",
    "ns.plot_activity_portrait(task_data)\n",
    "savethisfig(SPEC.FIGUREDIR + \"figure2/\", 'figure2_DVsweeps_activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns.clicks.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pbups_phys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
